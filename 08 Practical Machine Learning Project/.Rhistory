plot(x,y)
logfit <- glm(use ~ ., data = shuttle, family = binomial)
summary(logfit)
summary(shuttle)
shuttle1 <- shuttle
shuttle1$stability <- factor(shuttle1$stability)
summary(shuttle1)
str(shuttle)
str(shuttle1)
logfit <- glm(use ~ wind, data = shuttle, family = binomial)
summary(logfit)
shuttle2 <- mutate(shuttle,auto=1*(use=="auto"))
library(dplyr)
shuttle2 <- mutate(shuttle,auto=1*(use=="auto"))
View(shuttle2)
logfit <- glm(use ~ wind, data = shuttle2, family = binomial)
summary(logfit)
logfit <- glm(use ~ wind, data = shuttle2, family = binomial(link="logit"))
summary(logfit)
logfit <- glm(use ~ wind - 1, data = shuttle2, family = binomial(link="logit"))
summary(logfit)
summary(logfit)$coef
Coeffs <- summary(logreg1)$coef
Coeffs <- summary(logfit)$coef
Coeffs[1,1]
Coeffs[2,1]
exp(logfit$coef)
library(kernlab)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data("spam")
prediction <- ifelse(spam$your > 0.5,"spam","nonspam")
View(prediction)
View(spam$your)
table(prediction,spam$type)/length(spam$type)
?table
View(spam$type)
View(spam)
View(spam)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
install.packages("caret")
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
dim(training)
View(inTrain)
dim(inTrain)
dim(spam)
dim(training)
dim(testing)
?linspace
x<- c(1:20)
x
?rnd
select <- round( runif(10, 0, 1, 2 )
)
select <- (0,1,1,1,0,0,1,0,1,1)
select <- c(0,1,1,1,0,0,1,0,1,1)
x2<-x[select]
x2
x3<-x[-select]
x3<-x[-select]
x3
x2
select <- c(2,4,6,7)
x2<-x[select]
x2
x3<-x[-select]
x3
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
modelFit
install.packages("e1071")
set.seed(32343)
modelFit <- train(type ~.,data=training, method="glm")
modelFit
modelFit <- train(type ~.,data=training, method="glm")
modelFit$finalModel
predictions <- predict(modelFit,newdata=testing)
predictions
confusionMatrix(predictions,testing$type)
library(caret); library(kernlab); data(spam)
inTrain <- createDataPartition(y=spam$type,
p=0.75, list=FALSE)
training <- spam[inTrain,]
testing <- spam[-inTrain,]
hist(training$capitalAve,main="",xlab="ave. capital run length")
trainCapAve <- training$capitalAve
trainCapAveS <- (trainCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(trainCapAveS)
sd(trainCapAveS)
testCapAve <- testing$capitalAve
testCapAveS <- (testCapAve  - mean(trainCapAve))/sd(trainCapAve)
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("center","scale"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
mean(trainCapAveS)
testCapAveS <- predict(preObj,testing[,-58])$capitalAve
mean(testCapAveS)
sd(testCapAveS)
preObj <- preProcess(training[,-58],method=c("BoxCox"))
trainCapAveS <- predict(preObj,training[,-58])$capitalAve
par(mfrow=c(1,2)); hist(trainCapAveS); qqnorm(trainCapAveS)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
install.packages(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
trainIndex = createDataPartition(diagnosis,p=0.5,list=FALSE)
training = adData[trainIndex,]
testing = adData[trainIndex,]
training == testing
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
View(training)
library(Hmisc)
plot(mixtures$CompressiveStrength)
?cut2
mixtures$FlyAshclass<-cut2(mixtures$FlyAsh, g=10)
plot(mixtures$CompressiveStrength, col= mixtures$FlyAshclass)
plot(mixtures$CompressiveStrength, col= mixtures$FlyAshclass)
plot(mixtures$CompressiveStrength, col= mixtures$Age)
plot(mixtures$CompressiveStrength)
plot(mixtures$CompressiveStrength, col= mixtures$Age)
plot(mixtures$CompressiveStrength, col= mixtures$FlyAshclass)
plot(mixtures$CompressiveStrength, col= mixtures$Age)
mixtures$Ageclass<-cut2(mixtures$Age, g=10)
plot(mixtures$CompressiveStrength, col= mixtures$Ageclass)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
hist(mixtures$Superplasticizer)
log()
log(mixtures$Superplasticizer)
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
View(AlzheimerDisease)
View(adData)
View(training)
select(training, startsWith("IL"))
library(dplyr)
select(training, startsWith("IL"))
?select
select(training, starts_with("IL"))
IL_predictors<-select(training, starts_with("IL"))
View(IL_predictors)
Alz_IL<-cbind(adData$diagnosis, IL_predictors)
dim(adData$diagnosis)
dim(IL_predictors)
length(adData$diagnosis)
length(adData$IL_7)
length(training$diagnosis)
Alz_IL<-cbind(training$diagnosis, IL_predictors)
preProcess(training, method = "pca")
preProcess(Alz_IL, method = "pca")
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433); data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433); data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
testing = adData[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)data(AlzheimerDisease)
set.seed(3433); data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]; training = adData[ inTrain,]
testing = adData[-inTrain,]
IL_predictors<-select(training, starts_with("IL"))
Alz_IL<-cbind(training$diagnosis, IL_predictors)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=training)
View(training)
modelFit <- train(Alz_IL$diagnosis ~ .,method="glm",preProcess="pca",data=training)
modelFit <- train(Alz_IL$diagnosis ~ .,method="glm",preProcess="pca",data=Alz_IL)
Alz_IL$diagnosis
View(Alz_IL)
Alz_IL<-cbind(training$diagnosis, IL_predictors)
View(Alz_IL)
modelFit <- train(training$diagnosis ~ .,method="glm",preProcess="pca",data=Alz_IL)
rename(training$diagnosis = diagnosis, Alz_IL)
?rename
rename(Alz_IL, training$diagnosis = diagnosis)
rename(Alz_IL, training$diagnosis, diagnosis)
rename(Alz_IL, training$diagnosis =  diagnosis)
rename(Alz_IL, training$diagnosis ==  diagnosis)
rename(Alz_IL, "training$diagnosis" = "diagnosis")
rename(Alz_IL, training$diagnosis = "diagnosis")
colnames(Alz_IL)
colnames(Alz_IL)[1]
colnames(Alz_IL)[1] <- "diagnosis"
modelFit <- train(diagnosis ~ .,method="glm",preProcess="pca",data=Alz_IL)
confusionMatrix(testing$diagnosis,predict(modelFit,testing))
data(iris); library(ggplot2)
names(iris)
table(iris$Species)
?iris
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
qplot(Petal.Width,Sepal.Width,colour=Species,data=training)
?qplot
library(caret)
modFit <- train(Species ~ .,method="rpart",data=training)
print(modFit$finalModel)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("rattle")
library(rattle)
fancyRpartPlot(modFit$finalModel)
predict(modFit,newdata=testing)
View(training)
View(testing)
iris_compare<- (predict(modFit,newdata=testing) == testing$Species)
View(iris_compare)
?confusionMatrix
confusionMatrix(predict(modFit,newdata=testing), testing$Species)
dim(iris_compare==FALSE)
iris_compare==FALSE
select(iris_compare==FALSE)
length(iris_compare[iris_compare== FALSE])
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
install.packages("ElemStatLearn")
library(ElemStatLearn); data(ozone,package="ElemStatLearn")
ozone <- ozone[order(ozone$ozone),]
head(ozone)
library(ISLR)
install.packages("ISLR")
library(ISLR); data(Wage); library(ggplot2); library(caret);
Wage <- subset(Wage,select=-c(logwage))
View(Wage)
inTrain <- createDataPartition(y=Wage$wage, p=0.7, list=FALSE)
training <- Wage[inTrain,]; testing <- Wage[-inTrain,]
logwage
c(logwage)
data(Wage);
Wage <- subset(Wage,select=-c(logwage))
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
modFit <- train(wage ~ ., method="gbm",data=training,verbose=FALSE)
print(modFit)
qplot(predict(modFit,testing),wage,data=testing)
data(iris); library(ggplot2)
names(iris)
inTrain <- createDataPartition(y=iris$Species, p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
dim(training); dim(testing)
modlda = train(Species ~ .,data=training,method="lda")
modnb = train(Species ~ ., data=training,method="nb")
modnb = train(Species ~ ., data=training,method="nb")
plda = predict(modlda,testing); pnb = predict(modnb,testing)
table(plda,pnb)
equalPredictions = (plda==pnb)
qplot(Petal.Width,Sepal.Width,colour=equalPredictions,data=testing)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
View(segmentationOriginal)
inTrain <- subset(segmentationOriginal, segmentationOriginal$Case== "Train")
training <- iris[inTrain,]
training <- segmentationOriginal[inTrain,]
training <- subset(segmentationOriginal, segmentationOriginal$Case== "Train")
testing <- subset(segmentationOriginal, segmentationOriginal$Case== "Test")
View(testing)
dim(testing)
dim(training)
dim(segmentationOriginal)
set.seed(125)
modFit <- train(Class ~ .,method="rpart",data=training)
print(modFit$finalModel)
library(rattle)
fancyRpartPlot(modFit$finalModel)
install.packages("pgmm"); library(pgmm)
data(olive)
olive = olive[,-1]
View(olive)
data(olive)
dim(olive)
olive = olive[,-1]
dim(olive)
data(olive)
olive = olive[,-1]
modFit <- train(Area ~ .,method="rpart",data=olive)
newdata = as.data.frame(t(colMeans(olive)))
predict(modFit,newdata)
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
install.packages("ElemStatLearn")
require(devtools)
install_version("ggplot2", version = "0.9.1", repos = "http://cran.us.r-project.org")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
install.packages("devtools")
require(devtools)
install_version("ggplot2", version = "0.9.1", repos = "http://cran.us.r-project.org")
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
install.packages(c("backports", "boot", "class", "Hmisc", "isoband", "KernSmooth", "lattice", "MASS", "nlme", "nnet", "openxlsx", "pillar", "pkgbuild", "ps", "Rcpp", "RCurl", "rlang", "spatial", "survival", "tidyr", "tinytex", "withr", "xfun"))
require(devtools)
install.packages("devtools")
require(devtools)
install.packages("Rcpp")
install.packages("Rcpp")
require(devtools)
install.packages("~/Downloads/ElemStatLearn_2015.6.26.2.tar.gz", repos = NULL, type = "source")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
View(SAheart)
fit <- glm(chd ~ age + alcohol + obesity + tobacco + typea + ldl, SAheart, family=binomial())
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
missClass(trainSA, fit)
missClass(trainSA, predict(fit, type="response"))
missClass(trainSA$chd, predict(fit, type="response"))
missClass(testSA$chd, predict(fit, type="response"))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
View(vowel.test)
vowel.test$y <- as.factor(vowel.test$y)
vowel.train$y <- as.factor(vowel.train$y)
str(vowel.test)
set.seed(33833)
modFit <- train(y ~ .,data=vowel.train,method="rf",prox=TRUE)
modFit <- train(y ~ ., data=vowel.train, method="rf",prox=TRUE)
library(caret)
modFit <- train(y ~ ., data=vowel.train, method="rf",prox=TRUE)
modFit <- train(y ~ ., data=vowel.train, method="rf",prox=TRUE)
?varImp
varImp(modFit, scale = FALSE)
missClass(testSA$chd, predict(fit, trainSA, type="response"))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
missClass(trainSA$chd, predict(fit, newdata = trainSA))
missClass(trainSA$chd, predict(fit, newdata = trainSA), type="response")
missClass(trainSA$chd, type="response", predict(fit, newdata = trainSA))
missClass(trainSA$chd,  predict(fit, newdata = trainSA))
missClass(trainSA$chd,  predict(fit, newdata = testSA))
set.seed(13234)
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
missClass = function(values,prediction){sum(((prediction > 0.5)*1) != values)/length(values)}
set.seed(13234)
# definition of the training model
regModel <- train(chd~age+alcohol+obesity+tobacco+typea+ldl,data=trainSA,method="glm",family="binomial")
# computation of the misclasssification on the training set and test set
missClassTrain <- missClass(trainSA$chd,predict(regModel,newdata=trainSA))
missClassTest <- missClass(testSA$chd,predict(regModel,newdata=testSA))
missClassTrain
library(ElemStatLearn)
library(caret)
library(gbm)
library(AppliedPredictiveModeling)
library(lubridate) # For year() function below
library(AppliedPredictiveModeling)
library(readr)
pml_training <- read_csv("Documents/workspace/Git_Repositories/Coursera Data Science/datasciencecoursera Projects/08 Machine Learning Project/Data/pml-training.csv")
View(pml_training)
str(pml_training)
which( colnames(pml_training)=="$classe" )
which(colnames(pml_training)=="$classe" )
getColumnNumber(pml_training,"classe")
match("classe",names(pml_training))
unique(pml_training$classe)
unique(pml_training$kurtosis_roll_forearm)
View(pml_training)
View(pml_training)
unique(pml_training$skewness_yaw_arm)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
View(vowel.test)
str(vowel.test)
vowel.train$y<- as.factor(vowel.train$y)
str(vowel.test)
vowel.train$y<- as.factor(vowel.train$y)
str(vowel.train)
vowel.test$y<- as.factor(vowel.test$y)
str(vowel.test)
set.seed(33833)
fit<- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
library(caret)
fit<- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
fit_rf<- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
fit_bo<- train(y ~ ., method="gbm",data=vowel.train,verbose=FALSE)
fit_rf
pred_rf<-<- predict(fit_rf,vowel.test)
pred_rf<- predict(fit_rf,vowel.test)
pred_bo<- predict(fit_bo,vowel.test)
table(pred_bo,pred_rf)
pred_rf
table(pred_bo,pred_rf)
table(pred_bo,vowel.test$y)
pred_rftrain<-<- predict(fit_rf,vowel.train)
pred_rftrain<- predict(fit_rf,vowel.train)
table(pred_rftrain,vowel.train$y)
fit_rf
fit_rf$confusion
confusionMatrix(vowel.test$y,pred_rf)
confusionMatrix(vowel.test$y,pred_rf)
confusionMatrix(vowel.test$y,pred_bo)
set.seed(33833)
fit_rf<- train(y~ .,data=vowel.train,method="rf",prox=TRUE)
fit_bo<- train(y ~ ., method="gbm",data=vowel.train,verbose=FALSE)
pred_rf<- predict(fit_rf,vowel.test)
pred_bo<- predict(fit_bo,vowel.test)
confusionMatrix(vowel.test$y,pred_rf)
confusionMatrix(vowel.test$y,pred_bo)
pred_agree <- pred_bo==pred_rf
pred_agree
confusionMatrix(vowel.test$y,pred_rf[pred_bo==pred_rf])
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
confusionMatrix(pred_bo, vowel.test$y)$overall[1]
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
mod_rf <- train(y ~ ., data = vowel.train, method = "rf")
mod_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(mod_rf, vowel.test)
pred_gbm <- predict(mod_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
predDF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
sum(pred_rf[predDF$pred_rf == predDF$pred_gbm] ==
predDF$y[predDF$pred_rf == predDF$pred_gbm]) /
sum(predDF$pred_rf == predDF$pred_gbm)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
install.packages("Caret")
install.packages("caret")
install.packages("caret")
setwd("~/Documents/workspace/Git_Repositories/Coursera Data Science/datasciencecoursera Projects/08 Practical Machine Learning Project")
pwd
